---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# Welcome! 
I am now a PhD student at School of Computing in **National University of Singapore**. Fortunately, I will be supervised by Prof. Mong Li Lee and Prof. Wynne Hsu at Center for Trusted Internet and Community (CTIC). Prior to that, I received my master degree from **NUS** and bachelor degree from **Wuhan University**.

My research interest includes **Human-centered AI, Vision and Language, Multiomodal Sentiment Analysis, MLLM Reasoning.**

I am currently exploring new collaboration opportunities. If you are interested in any of the topics mentioned above, please feel free to reach out via **mluo@u.nus.edu**.

# üî• News
- **2025.01**: &nbsp;üéâ **Accepted at ICLR 2025**  
  <u>PAD: Personalized Alignment at Decoding-Time</u>.
  
- **2025.01**: &nbsp;üéâ **Accepted at WWW 2025**  
  <u>Towards Multimodal Empathetic Response Generation: A Rich Text-Speech-Vision Avatar-based Benchmark</u>.
  
- **2024.12**: &nbsp;**New Paper Published on arxiv**  
  <u>Aristotle: Mastering Logical Reasoning with A Logic-Complete Decompose-Search-Resolve Framework</u>.

- **2024.10**: &nbsp;**New Paper Published on arxiv**  
  <u>Effi-Code: Unleashing Code Efficiency in Language Models</u>.

- **2024.09**: &nbsp;**New Paper Published on arxiv**  
  <u>A Survey on Benchmarks of Multimodal Large Language Models</u>.

- **2024.08**: &nbsp;üéâ **Accepted at ACM MM Workshop (MIS24) (Oral, Best Paper Award)**  
  <u>Fine-grained Structural Hallucination Detection for Unified Visual Comprehension and Generation in Multimodal LLM</u>.

- **2024.07**: &nbsp;üéâ **Accepted at ACM MM 2024 (Oral)**  
  <u>PanoSent: A Panoptic Sextuple Extraction Benchmark for Multimodal Conversational Aspect-based Sentiment Analysis</u>.

- **2024.03**: &nbsp;üéâ **2nd Place at SemEval-2024**  
  <u>NUS-Emo at SemEval-2024 Task 3: Instruction-Tuning LLM for Multimodal Emotion-Cause Analysis in Conversations</u>.

- **2022.06**: &nbsp;**Accepted at TDSC**  
  <u>Towards Class-Balanced Privacy Preserving Heterogeneous Model Aggregation</u>.
  
# üìù Publications
- üéìDuring My PhD's Research Program

- üéìDuring My Master's Research Program

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM</div><img src='../images/panosent.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
    
[PanoSent: A Panoptic Sextuple Extraction Benchmark for Multimodal Conversational Aspect-based Sentiment Analysis](https://www.arxiv.org/pdf/2408.09481)

**Meng Luo**, Hao Fei, Bobo Li, Shengqiong Wu, Qian Liu, Soujanya Poria, Erik Cambria, Mong-Li Lee, Wynne Hsu

[**Project**](https://panosent.github.io/) | <strong>CCF-A Conference Paper</strong>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR</div><img src='../images/pad.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[PAD: Personalized Alignment at Decoding-Time](https://arxiv.org/pdf/2410.04070)

Ruizhe Chen, Xiaotian Zhang, **Meng Luo**, Wenhao Chai, Zuozhu Liu

[**Project**](https://arxiv.org/pdf/2410.04070) | <strong>CCF-A Conference Paper</strong>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">WWW</div><img src='../images/MERG.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[Towards Multimodal Empathetic Response Generation: A Rich Text-Speech-Vision Avatar-based Benchmark](https://openreview.net/pdf?id=36Qk76s74U)

Han Zhang, Zixiang Meng, **Meng Luo**, Hong Han, Lizi Liao, Erik Cambria, Hao Fei

[**Project**](https://openreview.net/pdf?id=36Qk76s74U) | <strong>CCF-A Conference Paper</strong>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">SemEval</div><img src='../images/nus-emo.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[NUS-Emo at SemEval-2024 Task 3: Instruction-Tuning LLM for Multimodal Emotion-Cause Analysis in Conversations](https://www.researchgate.net/profile/Hao-Fei-2/publication/380361877_NUS-Emo_at_SemEval-2024_Task_3_Instruction-Tuning_LLM_for_Multimodal_Emotion-Cause_Analysis_in_Conversations/links/6638a9cf08aa54017ae02fa0/NUS-Emo-at-SemEval-2024-Task-3-Instruction-Tuning-LLM-for-Multimodal-Emotion-Cause-Analysis-in-Conversations.pdf)

**Meng Luo**, Han Zhang, Shengqiong Wu, Bobo Li, Hong Han, Hao Fei

[**Project**](https://www.researchgate.net/profile/Hao-Fei-2/publication/380361877_NUS-Emo_at_SemEval-2024_Task_3_Instruction-Tuning_LLM_for_Multimodal_Emotion-Cause_Analysis_in_Conversations/links/6638a9cf08aa54017ae02fa0/NUS-Emo-at-SemEval-2024-Task-3-Instruction-Tuning-LLM-for-Multimodal-Emotion-Cause-Analysis-in-Conversations.pdf) | <strong> SemEval@ACL (Challenge, 2nd Place) 2024</strong>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">MM Workshop</div><img src='../images/mmworkshop.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[Fine-grained Structural Hallucination Detection for Unified Visual Comprehension and Generation in Multimodal LLM](https://dl.acm.org/doi/pdf/10.1145/3689090.3689388)

Hao Fei, **Meng Luo**, Jundong Xu, Shengqiong Wu, Wei Ji, Mong-Li Lee, Wynne Hsu

[**Project**](https://dl.acm.org/doi/pdf/10.1145/3689090.3689388) | <strong> Workshop@MM 2024</strong>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TDSC</div><img src='../images/TDSC.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[Towards Class-Balanced Privacy Preserving Heterogeneous Model Aggregation](https://ieeexplore.ieee.org/abstract/document/9796594/)

Xiaoyi Pang, Zhibo Wang, Zeqing He, Peng Sun, **Meng Luo**, Ju Ren

[**Project**](https://ieeexplore.ieee.org/abstract/document/9796594/) | <strong>CCF-A Journal Paper</strong>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arxiv</div><img src='../images/Aristotle.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[Aristotle: Mastering Logical Reasoning with A Logic-Complete Decompose-Search-Resolve Framework](https://arxiv.org/pdf/2412.16953)

Jundong Xu, Hao Fei, **Meng Luo**, Qian Liu, Liangming Pan, William Yang Wang, Preslav Nakov, Mong-Li Lee, Wynne Hsu

[**Project**](https://github.com/Aiden0526/Aristotle) | <strong>arxiv</strong>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arxiv</div><img src='../images/survey.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[A Survey on Benchmarks of Multimodal Large Language Models](https://arxiv.org/abs/2408.08632)

Jian Li, Weiheng Lu, Hao Fei, **Meng Luo**, Ming Dai, Min Xia, Yizhang Jin, Zhenye Gan, Ding Qi, Chaoyou Fu, Ying Tai, Wankou Yang, Yabiao Wang, Chengjie Wang

[**Project**](https://arxiv.org/abs/2408.08632) | <strong>arxiv</strong>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arxiv</div><img src='../images/efficode.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[Effi-Code: Unleashing Code Efficiency in Language Models](https://arxiv.org/pdf/2410.10209v1)

Dong Huang, Guangtao Zeng, Jianbo Dai, **Meng Luo**, Han Weng, Yuhao Qing, Heming Cui, Zhijiang Guo, Jie M. Zhang

[**Project**](https://arxiv.org/pdf/2410.10209v1) | <strong>arxiv</strong>
</div>
</div>

# üíª Professional Activity
Reviewer for ICLR, ICML, ACM MM, WWW, ACL, Neurocomputing, TOMM, TALLIP.

# üéñ Honors and Awards
### **During Undergraduate**

#### **Academic Achievements**
- 2022: Huawei Scholarship, Wuhan University (Top 5%)
- 2021: First-class Excellence Scholarship, Wuhan University (Ranked 2nd)
- 2021: Merit Student, Wuhan University (Top 10%)
- 2021: Outstanding Student, Wuhan University
  
#### **Competitions and Recognitions**
- 2022: Silver Award, Hubei Challenge Cup, Wuhan University
- 2022: Gold Award, Ziqiang Cup College, Wuhan University
- 2021: National First Prize, Citi Cup Financial Innovation Application Contest
- 2021: Bole Award, ByteTop Summit Project, ByteDance
- 2019: Top 10 Book Ambassador, Wuhan University Library
- 2018: The First Prize, HP Dream Factory Innovation Hackathon Wuhan Station, HP

#### **Leadership and Social Activities**
- 2021: Chairman, Wuhan University Campus Ambassador, ByteDance
- 2021: Excellent Campus Ambassador, WePie Team
- 2021: Online Course on Interdisciplinary Communication, University of Cambridge

------

<p align="center">
  <i> Wisdom begins in wonder.   ÁΩëÁΩóÂ§©‰∏ãÔºåÂπøÁªìÂêåÁõü„ÄÇ</i>
</p>
